<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Dracarys">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Dracarys">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Dracarys">






  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Dracarys</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Dracarys</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/16/DCGAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/10/16/DCGAN/" class="post-title-link" itemprop="url">DCGAN</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-10-16 00:57:01" itemprop="dateCreated datePublished" datetime="2019-10-16T00:57:01+08:00">2019-10-16</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 09:07:19" itemprop="dateModified" datetime="2019-10-21T09:07:19+08:00">2019-10-21</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="DCGAN-教程"><a href="#DCGAN-教程" class="headerlink" title="DCGAN 教程"></a><a href="http://pytorch123.com/SixthSection/Dcgan/" target="_blank" rel="noopener">DCGAN 教程</a></h1><h2 id="什么是GAN"><a href="#什么是GAN" class="headerlink" title="什么是GAN"></a>什么是GAN</h2><p>GANs是由Lan Goodfellow 于2014年提出。</p>
<ul>
<li><p>判别器的符号定义</p>
<p>  设$x$代表一张图像数据， $D(x)$是判别器网络，它输出$x$是来自训练数据而不是生成器的概率。</p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/06/DIY主机-系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/07/06/DIY主机-系统/" class="post-title-link" itemprop="url">DIY主机+系统</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-06 08:47:52 / 修改时间：09:43:13" itemprop="dateCreated datePublished" datetime="2019-07-06T08:47:52+08:00">2019-07-06</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="组装电脑遇到的坑"><a href="#组装电脑遇到的坑" class="headerlink" title="组装电脑遇到的坑"></a>组装电脑遇到的坑</h2><h3 id="内存安装"><a href="#内存安装" class="headerlink" title="内存安装"></a>内存安装</h3><p>主板(msiB450)上有4个DIMM插槽，我有两条内存。一开始我把内存插在靠近cpu的两个插槽<br>上，电脑开不了机，主板显示内存问题。拔掉任意一条内存都可以正常开机。后来看了主板<br>说明书才知道，<strong>插槽分为DIMM1和DIMM2，从靠近CPU的位置数起，4个插槽分别微DIMMA1,<br>DIMMA2, DIMMB1, DIMMB2。安装内存条必须先由DIMMA2插槽开始安装,如果安装两条内存建<br>议是DIMMA2和DIMMB2</strong>， 这样按说明书装在DIMMA2和DIMMB2后顺利开机。</p>
<h2 id="双SSD双系统安装"><a href="#双SSD双系统安装" class="headerlink" title="双SSD双系统安装"></a>双SSD双系统安装</h2><p><strong><em>电脑上装了两块SSD， 计划一块装windows， 一快装Ubuntu。</em></strong></p>
<h3 id="在其中一块盘上装好windows"><a href="#在其中一块盘上装好windows" class="headerlink" title="在其中一块盘上装好windows"></a>在其中一块盘上装好windows</h3><p>由于只有独显，需要把显示器接到显卡输出口才有显示。</p>
<h3 id="UltrOS-制作UbuntuU盘启动盘"><a href="#UltrOS-制作UbuntuU盘启动盘" class="headerlink" title="UltrOS 制作UbuntuU盘启动盘"></a>UltrOS 制作UbuntuU盘启动盘</h3><p>记得选RAM</p>
<h3 id="用U盘安装Ubuntu"><a href="#用U盘安装Ubuntu" class="headerlink" title="用U盘安装Ubuntu"></a>用U盘安装Ubuntu</h3><ul>
<li>开机按Delete进入BIOS选择U盘启动（把U盘优先级调到最高）</li>
<li><p>电脑只有Nvidia显卡，安装Ubuntu会黑屏，这是因为ubuntu对显卡的支持有关，需要手动<br>添加显卡选项:<code>nomodeset</code>，使其支持Nvidia系列显卡。</p>
</li>
<li><p>进入安装时，光标移动到<code>install ubuntu</code>，按<code>e</code>进入编辑模式，进入命令行模式,找<br>到<code>quite splash</code>然后去掉<code>--</code>后，添加<code>nomodeset</code>（依照不同显卡进行不同显卡<br>驱动选项的添加，我们使用的是Nvidia显卡，添加nomodeset）F10安装</p>
</li>
<li><p>安装结束后，重启时，电脑此时的启动顺序是U盘&gt;windows盘&gt;linux盘，<br>  所以我们需要进入BIOS调整启动顺序为linux盘&gt;windows盘&gt;U盘。</p>
</li>
<li><p>顺利进入grub画面后，按<code>e</code> 进入编辑开机指令的模式, 同样找到<code>quitesplash</code>并在<br>后面加上<code>nomodeset</code>，按F10启动系统。</p>
</li>
<li><p>为了避免每次开机都要改启动命令，我们需要永久修改grub启动命令。开机后进入系统<br>打开终端</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/default/grub</span><br></pre></td></tr></table></figure>
<p>  按<code>i</code>进入vi的编辑模式</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash&quot;</span><br><span class="line">#修改为：</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash nomodeset&quot;</span><br></pre></td></tr></table></figure>
<p>  按<code>esc</code>, 输入<code>:wq!</code>保存， 更新grub</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-grub</span><br></pre></td></tr></table></figure>
</li>
<li><p>在重启之前，我们发现电脑屏幕分辨率不是最佳（如果分辨率正常，则不用）</p>
</li>
</ul>
<p>点击右上角“系统设置—&gt;软件和更新—&gt;附加驱动”选择使用Nvidia驱动</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>微星主板说明书</p>
<p><a href="https://blog.csdn.net/cheneykl/article/details/79111618" target="_blank" rel="noopener">安装ubuntu时黑屏三种解决办法</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/08/GNN-pooling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/08/GNN-pooling/" class="post-title-link" itemprop="url">Differentiable Pooling</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-08 14:22:17" itemprop="dateCreated datePublished" datetime="2019-04-08T14:22:17+08:00">2019-04-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-21 09:03:45" itemprop="dateModified" datetime="2019-10-21T09:03:45+08:00">2019-10-21</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>A major limitation of current GNN architectures is that they are inherently<br><em>flat</em> as they only propagate information across the edges of the graph and<br>unable to infer and aggregate the information in a <em>hierarchical</em> way. This<br>lack of hierarchical structure is especially problematic of the task of<br>graph classification, where the goal is to predict the label associated with<br>an entire graph.</p>
<p>The challenge in the GNN setting—compared to standard CNNs—is that graphs<br>contain no natural notion of spatial locality.</p>
<h2 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h2><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p>We represent a graph $G$ as $(A, F)$, where $A \in \{0, 1\}^{n\times{n}}$ is the adjacency matrix, and $F \in \mathbb{R}^{n\times{d}}$</p>
<p><strong>Graph neural networks</strong></p>
<script type="math/tex; mode=display">H^{(k)} = M(A,H^{(k-1)};\theta^{(k)}),</script><p>GCNs:</p>
<script type="math/tex; mode=display">H^{(k)} =  ReLU(\tilde{D}^{-\frac{1}{2}}) \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(k-1)}W^{(k-1)},</script><p><strong>Stacking GNNs and pooling layers</strong></p>
<p>The goal is to learn how to cluster or pool together nodes using the output of<br>a GNN, so that we can use this coarsened graph as input to another GNN layer.</p>
<h3 id="Differentiable-Pooling-via-Learned-Assignments"><a href="#Differentiable-Pooling-via-Learned-Assignments" class="headerlink" title="Differentiable Pooling via Learned Assignments"></a>Differentiable Pooling via Learned Assignments</h3><p><strong>Pooling with an assignment matrix</strong></p>
<script type="math/tex; mode=display">S^{(l)} \in \mathbb{R}^{n_l\times{n_{l+1}}}</script><p>Each row of $S^{(l)}$ corresponds to one of the $ n_l$ nodes(or clusters) at<br>layer $l$, and each column of $S^{l}$ corresponds to one of the $n_{l+1}$<br>clusters at the next layer $l+1$. Intuitively, $S^{(l)}$ provides a soft<br>assignment of each node at layer $l$ to a cluster in the next coarsened layer<br>$l + 1$</p>
<script type="math/tex; mode=display">(A^{(l+1)}, w^{(l+1)})= DIFFPOOL(A^{(l)}, Z^{(l)})</script><p>In particular, we apply the two following equations:</p>
<script type="math/tex; mode=display">X^{(l+1)} = {S^{(l)}}^TZ^{(l)}</script><script type="math/tex; mode=display">A^{(l+1)} = {S^{(l)}}^TA^{(l)}S^{(l)}</script><p><strong>Leaning the assignment matrix</strong></p>
<script type="math/tex; mode=display">Z^{(l)}=GNN_{l,embed}(A^{(l)}, X^{(l)})</script>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/04/GCNnote/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/GCNnote/" class="post-title-link" itemprop="url">GCN Note</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 13:29:11" itemprop="dateCreated datePublished" datetime="2019-04-04T13:29:11+08:00">2019-04-04</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-08 14:22:00" itemprop="dateModified" datetime="2019-04-08T14:22:00+08:00">2019-04-08</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="A-brief-history-of-Graph-Neural-Networks"><a href="#A-brief-history-of-Graph-Neural-Networks" class="headerlink" title="A brief history of Graph Neural Networks"></a>A brief history of Graph Neural Networks</h3><ul>
<li>The notation of graph neural networks was firstly outlined in Gori et al.<br>  (2005)</li>
<li><p>And further elaborated in Micheli (2009) and Scarselli et al. (2009)</p>
<p>  These early studies learn a target node’s representation by<br>  propagating neighbor information via recurrent neural architectures in<br>  an iterative manner until a stable fixed points is reached. This process is<br>  computationally expensive.</p>
</li>
<li>The first prominent research on GCNs is presented in Bruna et al.(2013),<br>  which develops a variant of graph convolution based on spectral graph<br>  theory.</li>
<li>In addition to graph convolutional networks, many alternative graph<br>  neural networks have been developed in the past few years. These approaches<br>  include graph attention networks, graph autoencoders, graph generative<br>  networks, and graph spatial-temporal networks.</li>
</ul>
<h3 id="Graph-neural-network-vs-Network-embedding"><a href="#Graph-neural-network-vs-Network-embedding" class="headerlink" title="Graph neural network vs. Network embedding"></a>Graph neural network vs. Network embedding</h3><p>Many network embedding algorithms are typically unsupervised algorithms and<br>they can be broadly classified into three groups: matrix factorization, random<br>walks, and deep learning approaches.</p>
<p>The deep learning approaches for network embedding at the same time belong to<br>graph neural networks, which include graph antoencoder-based algorithms(e.g.,<br>DNGR and SDNE) and graph convolutional neural networks with unsupervised<br>training(e.g., GraphSage).</p>
<p><img src="/images/NEvsGNN.png" alt="NEvsGNN"><br><em>Fig. 1:Network Embedding v.s. Graph Neural Networks.</em></p>
<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p><em>Spatial-Temporal Graph</em> A spatial-temporal graph is an attributed graph where the feature matrix $\textbf{X}$ evolves over time. It is defined as $\mathcal{G} = (\textbf{V,E,A,X})$ with $\textbf{X}\in\textbf{R}^{T\times{N}\times{D}}$ where $T$ is the length of time steps.</p>
<h2 id="Gategorization-and-Frameworks"><a href="#Gategorization-and-Frameworks" class="headerlink" title="Gategorization and Frameworks"></a>Gategorization and Frameworks</h2><h3 id="Taxonomy-of-GNNs"><a href="#Taxonomy-of-GNNs" class="headerlink" title="Taxonomy of GNNs"></a>Taxonomy of GNNs</h3><ul>
<li><p>Graph Convolution Networks(GCNs)</p>
<p>  The key is to learn a function $f$ to generate a node $v_i’$ representation by aggregating its own features $\textbf{X}_i$ and neighbors’ features $\textbf{X}_j$, where $j \in N(v_i)$.</p>
</li>
<li><p>Graph Attention Networks</p>
<p>  Are similar to GCNs and seek an aggregation function to fuse the neighboring nodes, random walks, and candidate models in graphs to learn a new representations.<br>  <img src="/images/GCNvsGAN.png" alt="GCNvsGAN"><br>  <em>Fig. 2:Graph Convolution Network v.s. Graph Attention Network</em></p>
</li>
<li>Graph Auto-encoders</li>
<li>Graph Generative Networks</li>
<li>Graph Spatial-temporal Networks</li>
</ul>
<h3 id="Frameworks"><a href="#Frameworks" class="headerlink" title="Frameworks"></a>Frameworks</h3><ul>
<li>Node-level</li>
<li>Edge-level</li>
<li><p>Graph-level</p>
<p> pooling operations</p>
</li>
</ul>
<p><strong>Supervised learning for graph-level classification</strong></p>
<p>Graph convolutional layer -&gt; pooling layer -&gt; linear layer -&gt; softmax layer</p>
<h2 id="Graph-Convolution-Network"><a href="#Graph-Convolution-Network" class="headerlink" title="Graph Convolution Network"></a>Graph Convolution Network</h2><h3 id="Spectral-based-Graph-Convolutional-Networks"><a href="#Spectral-based-Graph-Convolutional-Networks" class="headerlink" title="Spectral-based Graph Convolutional Networks"></a>Spectral-based Graph Convolutional Networks</h3><h3 id="Spatial-based-Graph-Convolutional-Networks"><a href="#Spatial-based-Graph-Convolutional-Networks" class="headerlink" title="Spatial-based Graph Convolutional Networks"></a>Spatial-based Graph Convolutional Networks</h3><h3 id="Graph-Pooling-Modules"><a href="#Graph-Pooling-Modules" class="headerlink" title="Graph Pooling Modules"></a>Graph Pooling Modules</h3><p>Similar to the original pooling layer which comes with CNNs, graph pooling module, is also of vital importance, particularly for graph level classification tasks.</p>
<script type="math/tex; mode=display">h_G = \textit{mean/max/sum}(h_1^T, h_2^T, ..., h_n^T)</script>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/04/markdownskill/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/markdownskill/" class="post-title-link" itemprop="url">Markdown 表格中转义"|"</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 12:16:13 / 修改时间：12:27:50" itemprop="dateCreated datePublished" datetime="2019-04-04T12:16:13+08:00">2019-04-04</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在markdown中使用表格时，如果表格内容中出现“|”，通常会和表格本身冲突。<br>解决办法：用html转义字符代替，”|”的转义字符是<code>&amp;#124;</code></p>
<p>例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">字符     | 描述</span><br><span class="line">:--------|:--</span><br><span class="line">a&amp;#124;b | a或者b</span><br></pre></td></tr></table></figure></p>
<p>显示为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">字符</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">a&#124;b</td>
<td style="text-align:left">a或者b</td>
</tr>
</tbody>
</table>
</div>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><a href="https://www.jianshu.com/p/55b9ce58bf6c" target="_blank" rel="noopener">markdown表格不能转义”|”解决办法</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/04/vimskill/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/vimskill/" class="post-title-link" itemprop="url">Vim 学习</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 12:01:44 / 修改时间：16:57:12" itemprop="dateCreated datePublished" datetime="2019-04-04T12:01:44+08:00">2019-04-04</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="在vim中替换"><a href="#在vim中替换" class="headerlink" title="在vim中替换"></a>在vim中替换</h3><p><code>:s</code>（substitute）命令用来查找和替换字符串。语法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:&#123;作用范围&#125;s/&#123;目标&#125;/&#123;替换&#125;/&#123;替换标志&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><a href="https://harttle.land/2016/08/08/vim-search-in-file.html" target="_blank" rel="noopener">在 Vim 中优雅地查找和替换</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/04/gif-on-mac/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/gif-on-mac/" class="post-title-link" itemprop="url">Gif on Mac</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 10:16:29 / 修改时间：12:06:52" itemprop="dateCreated datePublished" datetime="2019-04-04T10:16:29+08:00">2019-04-04</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>很多readme里面都有gif文件，如何把mov 或者<br>mp4等其他格式文件转换成gif呢？这里介绍用终端+命令行的方式实现mov等其他格式到gif的转换。</p>
<h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><ul>
<li><p>homebrew</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-select --install /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>node.js</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install node</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><ul>
<li><p>gifify</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o /usr/local/bin/gifify -O https://raw.githubusercontent.com/jclem/gifify/master/gifify.sh &amp;&amp; chmod +x /usr/local/bin/gifify</span><br></pre></td></tr></table></figure>
</li>
<li><p>FFmpeg</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install ffmpeg --with-libass --with-fontconfig</span><br></pre></td></tr></table></figure>
</li>
<li><p>convert</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install imagemagick --with-fontconfig</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gifify -o test test.mov</span><br></pre></td></tr></table></figure>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><a href="https://talk.ninghao.net/t/zai-mac-shang-ba-lu-zhi-de-ping-mu-shi-pin-zhuan-cheng-gif-dong-hua/598" target="_blank" rel="noopener">在 Mac 上把录制的屏幕视频转成 Gif 动画</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/04/regularexpression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/04/regularexpression/" class="post-title-link" itemprop="url">Regularexpression</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-04 09:52:21 / 修改时间：12:14:36" itemprop="dateCreated datePublished" datetime="2019-04-04T09:52:21+08:00">2019-04-04</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">字符</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">(?:pattern)</td>
<td style="text-align:left">匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (&#124;) 来组合一个模式的各个部分是很有用。例如， ‘industr(?:y&#124;ies) 就是一个比 ‘industry&#124;industries’ 更简略的表达式。</td>
</tr>
<tr>
<td style="text-align:left">?</td>
<td style="text-align:left">当该字符紧跟在任何一个其他限制符(*,+,?,{n},{n,},{n,m})后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串”oooo”，’o+?’将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。</td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/02/latex/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/02/latex/" class="post-title-link" itemprop="url">Latex Tutorial</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-02 14:32:18 / 修改时间：20:16:47" itemprop="dateCreated datePublished" datetime="2019-04-02T14:32:18+08:00">2019-04-02</time>
            

            
              

              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="实现中英文混排"><a href="#实现中英文混排" class="headerlink" title="实现中英文混排"></a>实现中英文混排</h2><p><a href="https://www.kancloud.cn/thinkphp/latex/41810" target="_blank" rel="noopener">实现中英文混排·一份其实很短的latex入门文档</a></p>
<ol>
<li><p>使用XeLateX, 配置vimtex如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">let g:Tex_CompileRule_pdf = &apos;xelatex --interaction=nonstopmode $*&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>tex文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage[UTF8]&#123;ctex&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">你好\textbf&#123;xxxx&#125;xxx\textit&#123;xxx&#125;\underline&#123;xxx&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="latex-如何插入参考文献"><a href="#latex-如何插入参考文献" class="headerlink" title="latex 如何插入参考文献"></a>latex 如何插入参考文献</h2><h2 id="如何生成和加载latex模版"><a href="#如何生成和加载latex模版" class="headerlink" title="如何生成和加载latex模版"></a>如何生成和加载latex模版</h2>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/02/BatchNormalization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thylakoids">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dracarys">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/02/BatchNormalization/" class="post-title-link" itemprop="url">BatchNormalization</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-02 14:11:23" itemprop="dateCreated datePublished" datetime="2019-04-02T14:11:23+08:00">2019-04-02</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-04 12:33:08" itemprop="dateModified" datetime="2019-04-04T12:33:08+08:00">2019-04-04</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Why-do-we-need-batch-normalization"><a href="#Why-do-we-need-batch-normalization" class="headerlink" title="Why do we need batch normalization?"></a>Why do we need batch normalization?</h2><p>We normalize the input layer by adjusting and scaling the activations. For example, when we have features from 0 to 1 and some from 1 to 1000, we should normalize them to speed up learning. If the input layer is benefiting from it, why not do the same thing also for the values in the hidden layers, that are changing all the time, and get 10 times or more improvement in the training speed.</p>
<p>Batch normalization reduces the amount by what the hidden unit values shift around (covariance shift). To explain covariance shift, let’s have a deep network on cat detection. We train our data on only black cats’ images. So, if we now try to apply this network to data with colored cats, it is obvious; we’re not going to do well. The training set and the prediction set are both cats’ images but they differ a little bit. In other words, if an algorithm learned some X to Y mapping, and if the distribution of X changes, then we might need to retrain the learning algorithm by trying to align the distribution of X with the distribution of Y. ( Deeplearning.ai: Why Does Batch Norm Work?<a href="https://www.youtube.com/watch?v=nUUqwaxLnWs" target="_blank" rel="noopener">C2W3L06</a></p>
<p>Also, batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers.</p>
<h2 id="How-dose-batch-normalization-work"><a href="#How-dose-batch-normalization-work" class="headerlink" title="How dose batch normalization work?"></a>How dose batch normalization work?</h2><p>Batch normalization layer is usually used <strong>before</strong> the activation layer.</p>
<p>The basic idea is doing the normalization then applying a linear and shif to the mini-batch:</p>
<p>For input mini-batch <script type="math/tex">B = \{x_{1, ..., m}\}</script>, we want to learn the parameter $\gamma$ and $\beta$. The output of the layer is <script type="math/tex">\{y_i = BN_{\gamma, \beta}(x_i)\}</script>, where:</p>
<script type="math/tex; mode=display">\mu_B \leftarrow \frac{1}{m}\sum_{i = 1}^{m}x_i</script><script type="math/tex; mode=display">\sigma_B^2 \leftarrow \frac{1}{m}\sum_{i=1}^m(x_i - \mu_B)^2</script><script type="math/tex; mode=display">\hat{x_i} \leftarrow \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}</script><script type="math/tex; mode=display">y_i \leftarrow \gamma \hat{x_i} + \beta \equiv BN_{\gamma,\beta}(x_i)</script><p><strong>Usual batchnorm</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># t is the incoming tensor of shape [B, H, W, C]</span></span><br><span class="line"><span class="comment"># mean and stddev are computed along 0 axis and have shape [H, W, C]</span></span><br><span class="line">mean = mean(t, axis=<span class="number">0</span>)</span><br><span class="line">stddev = stddev(t, axis=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">0.</span>.B<span class="number">-1</span>:</span><br><span class="line">  out[i,:,:,:] = norm(t[i,:,:,:], mean, stddev)</span><br></pre></td></tr></table></figure></p>
<p>Ba/sically, it computes <code>H*W*C</code> means and <code>H*W*C</code> standard deviations across B<br>elements. You may notice that different elements at different spatial locations<br>have their own mean and variance and gather only <code>B</code> values.</p>
<p><strong>Batchnorm in conv layer</strong></p>
<p>This way is totally possible. But the convolutional layer has a special property: filter weights are shared across the input image (you can read it in detail in this <a href="http://cs231n.github.io/convolutional-networks/#conv" target="_blank" rel="noopener">post</a>. That’s why it’s reasonable to normalize the output in the same way, so that each output value takes the mean and variance of B<em>H</em>W values, at different locations.</p>
<p>Here’s how the code looks like in this case (again pseudo-code):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># t is still the incoming tensor of shape [B, H, W, C]</span></span><br><span class="line"><span class="comment"># but mean and stddev are computed along (0, 1, 2) axes and have just [C] shape</span></span><br><span class="line">mean = mean(t, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">stddev = stddev(t, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">0.</span>.B<span class="number">-1</span>, x <span class="keyword">in</span> <span class="number">0.</span>.H<span class="number">-1</span>, y <span class="keyword">in</span> <span class="number">0.</span>.W<span class="number">-1</span>:</span><br><span class="line">  out[i,x,y,:] = norm(t[i,x,y,:], mean, stddev)</span><br></pre></td></tr></table></figure></p>
<p>In total, there are only <code>C</code> means and standard deviations and each one of them is computed over <code>B*H*W</code> values. That’s what they mean when they say “effective mini-batch”: the difference between the two is only in axis selection (or equivalently “mini-batch selection”).</p>
<h2 id="Batch-Normalization-in-Pytorch"><a href="#Batch-Normalization-in-Pytorch" class="headerlink" title="Batch Normalization in Pytorch"></a>Batch Normalization in Pytorch</h2><p> <a href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" target="_blank" rel="noopener">This link</a> provides a nice explanation of how to derive backpropagation gradients for batch normalization. Let’s see it in action now:</p>
<p> <strong>Batch Normalization for 2D data</strong></p>
<p> Let’s start with 1D normalization.<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br></pre></td></tr></table></figure></p>
<p>Let’s define X and calculate its mean and variance. Note that X has size (20,100) which means it has 20 samples with each sample having 100 features (or dimensions). For normalizing, we need to look across all samples. In other words, we normalize across 20 values for each dimension (with each value coming on a sample).<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">20</span>,<span class="number">100</span>) * <span class="number">5</span> + <span class="number">10</span></span><br><span class="line">X = Variable(X)</span><br><span class="line"></span><br><span class="line">mu = torch.mean(X[:,<span class="number">1</span>])</span><br><span class="line">var_ = torch.var(X[:,<span class="number">1</span>], unbiased=<span class="keyword">False</span>)</span><br><span class="line">sigma = torch.sqrt(var_ + <span class="number">1e-5</span>)</span><br><span class="line">x = (X[:,<span class="number">1</span>] - mu)/sigma</span><br></pre></td></tr></table></figure></p>
<p>Note that in the line above we set unbiased = False while calculating var_. This is to prevent Bessel’s correction. In other words, we want to divide by N and not N-1 while calculating the variance. x is the same as the result of batch normalization. Also note that in the code below we set affine = False. This is to prevent creation of parameters γ(k), β(k) which may scale and shift normalized data again. While training, affine is set to True.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">B = nn.BatchNorm1d(<span class="number">100</span>, affine=<span class="keyword">False</span>)</span><br><span class="line">y = B(X)</span><br><span class="line">print(x.data / y[:,<span class="number">1</span>].data)</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.0000</span><br><span class="line">1.0000</span><br><span class="line">1.0000</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>This also works for 3D input.</p>
<p><strong>Batch Normalization for 3D inputs</strong></p>
<p>Let’s define some 3D data with 4 and variance 4:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x3 = torch.randn(<span class="number">150</span>, <span class="number">20</span>, <span class="number">100</span>) * <span class="number">2</span> + <span class="number">4</span></span><br><span class="line">x3 = Variable(x3)</span><br><span class="line">B2 = nn.BatchNorm1d(<span class="number">20</span>)</span><br></pre></td></tr></table></figure></p>
<p>Note that here we did not set <code>affine = False</code>. Instead, we can manually set<br>those values to what we want. To preserve normalization, we want    γ(k) = 1 and<br>β(k) = 0. These values are stored in parameters weight and bias of the<br>BatchNorm variable.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">B2.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">B2.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line">Y = B2(X3)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Manual calculation</span></span><br><span class="line">mu = X3[:,<span class="number">0</span>,:].mean()</span><br><span class="line">sigma = torch.sqrt(torch.var(X3[:,<span class="number">0</span>,:], unbiased=<span class="keyword">False</span>) + <span class="number">1e-5</span>)</span><br><span class="line">X_normalized = (X3[:,<span class="number">0</span>,:] - mu)/sigma</span><br></pre></td></tr></table></figure></p>
<p>In the above example, X_normalized has the same values as Y[:,0,:].</p>
<p><strong>Batch Normalization for images(or any 4D input)</strong></p>
<p>A batch of RGB images has four dimensions: (B,C,X,Y) or (B,X,Y,C) where B is batch number, C is channel number, and X, Y are locations.</p>
<p>Batch normalization in images is done along the channel axis.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">5</span>,<span class="number">25</span>,<span class="number">100</span>,<span class="number">100</span>) * <span class="number">2</span> + <span class="number">4</span></span><br><span class="line">X = Variable(X)</span><br><span class="line">B = nn.BatchNorm2d(<span class="number">25</span>, affine=<span class="keyword">False</span>)</span><br><span class="line">Y = B(X)</span><br></pre></td></tr></table></figure></p>
<p>Here <code>Y[:,i,:,:]</code> is the same as <code>((X[:,i,:,:] - X[:,i,:,:].data.mean())/((X[:,i,:,:].data.var(unbiased=False) + 1e-5)**0.5))</code> for all valid values of.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c" target="_blank" rel="noopener">Batch normalization in Neural Networks</a></p>
<p><a href="https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network" target="_blank" rel="noopener">Batch Normalization in Convolutional Neural Network</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">thylakoids</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">thylakoids</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>




  

  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>


  
  



  




  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: "AMS"
      }
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
      for (i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
  overflow: auto hidden;
}
</style><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

</body>
</html>
